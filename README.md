# Sistema de Evaluaci贸n por IA

Esta soluci贸n es un ecosistema de reclutamiento inteligente dise帽ado para automatizar la evaluaci贸n t茅cnica de candidatos mediante modelos de lenguaje de gran escala (LLM). El sistema, orquestado con LangChain, ejecuta un flujo de dos fases: an谩lisis aut贸nomo de compatibilidad y entrevista interactiva de validaci贸n de requisitos.

## Arquitectura del Sistema

El sistema sigue una arquitectura de microservicios contenerizada para garantizar escalabilidad, portabilidad y desacoplamiento t茅cnico:

### Componentes Principales

*   **Frontend (`src/frontend/app.py`)**: Interfaz unificada construida con Streamlit. Incluye:
    *   **Portal del Candidato**: Registro de identidad (Nombre, Apellidos y DNI/Pasaporte) y ejecuci贸n de pruebas.
    *   **Panel del Evaluador**: Acceso a Informes Ejecutivos detallados con persistencia de datos.
*   **Backend (`src/backend/engine.py`)**: API robusta en FastAPI que gestiona la l贸gica de negocio, los agentes de LangChain y el procesamiento de lenguaje natural.
*   **Data Layer**: Persistencia local en `/data/reports/` para auditor铆a y consulta de resultados en formato JSON y TXT.

##  L贸gica de Negocio y Evaluaci贸n

El n煤cleo del sistema utiliza LangChain para garantizar un procesamiento agn贸stico del modelo y estructurado de la informaci贸n.

### 1. Reglas de Puntuaci贸n y Descarte

*   **Identificaci贸n Un铆voca**: Se registra Nombre, Apellidos y DNI o Pasaporte para vincular cada informe ejecutivo a un candidato real.
*   **Fragmentaci贸n At贸mica**: Los requisitos compuestos se desglosan en unidades individuales para una evaluaci贸n precisa (ej. "FastAPI y LangChain" cuentan como dos 铆tems).
*   **C谩lculo de Score**: Cada requisito tiene un peso equitativo sobre el 100% de la oferta.
*   **Filtro de Descarte Cr铆tico**: Si un requisito marcado como M铆nimo o Obligatorio no se identifica en el perfil, el score se fija en 0% y el candidato es descartado autom谩ticamente.
*   **Gesti贸n de Informaci贸n Faltante**: Los requisitos no encontrados en el CV se derivan a un agente de entrevista que interact煤a con el candidato para intentar recuperar esos puntos en el score final.

### 2. Rec谩lculo Din谩mico (Fase 2)

Tras la entrevista, el sistema procesa la transcripci贸n y actualiza la puntuaci贸n final (ej. de un 50% inicial a un 75% si se valida un requisito extra en la charla).

##  Ejecuci贸n con Docker

El proyecto est谩 completamente dockerizado para permitir una ejecuci贸n inmediata en cualquier entorno.

### Pasos de Despliegue

1.  **Variables de Entorno**: Configura el archivo `.env` en la ra铆z del proyecto:
    ```env
    OPENAI_API_KEY=tu_clave_api_aqui
    LLM_PROVIDER=openai
    LLM_MODEL=gpt-4o
    ```
2.  **Construir y Ejecutar**:
    ```bash
    docker-compose up --build
    ```
3.  **Acceso**:
    *   **Aplicaci贸n Web (Streamlit)**: [http://localhost:8501](http://localhost:8501)
    *   **Documentaci贸n API (FastAPI)**: [http://localhost:8000/docs](http://localhost:8000/docs)

## Informe Ejecutivo

El evaluador dispone de un panel privado donde, al seleccionar a un candidato por su identidad, puede visualizar:

*   **Estado Final**: Apto o Descartado por requisito obligatorio.
*   **Evoluci贸n del Score**: Comparativa entre la fase de an谩lisis de CV y el resultado tras la entrevista.
*   **Evidencia T茅cnica**: Desglose detallado de requisitos cumplidos y confirmados por voz/chat.

Desarrollado como soluci贸n t茅cnica de evaluaci贸n de talento.

## Desarrollo Local

Si prefieres correrlo sin Docker:

1.  Crear entorno virtual: `python -m venv .venv`
2.  Activar: `.\.venv\Scripts\Activate` (Windows)
3.  Instalar dependencias: `pip install -r requirements.txt`
4.  Correr Backend:
    ```bash
    uvicorn evaluador-tecnico.src.backend.engine:app --reload
    ```
5.  Correr Frontend:
    ```bash
    streamlit run evaluador-tecnico/src/frontend/app.py
    ```

